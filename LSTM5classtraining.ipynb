{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qZr50Dc8P9F",
        "outputId": "20f745c1-fa83-498a-ab7b-3f59738ee32a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2yDnjxWMQ5gR",
        "outputId": "d2cad62f-a3bd-45fc-c761-1dce83758f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras==2.13.1\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.0 requires keras>=3.2.0, but you have keras 2.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.13.1\n",
            "Collecting tensorflow==2.13.1\n",
            "  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.1)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (3.11.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (18.1.1)\n",
            "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.1)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.1)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.1)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (2.4.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.1)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.1) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.1)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.2.2)\n",
            "Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, numpy, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.34 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.14 requires typing-extensions>=4.9.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\n",
            "pydantic 2.9.1 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.13.1 which is incompatible.\n",
            "torch 2.4.0+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.3.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.1 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "09792240bef14e19a0699951d9ace77d",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install keras==2.13.1\n",
        "!pip install tensorflow==2.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGilmUq8h8Fy"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Model,Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import LSTM, Dense, BatchNormalization, Dropout\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "# from clr_callback import *\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3Vl2zg47UC",
        "outputId": "e00d5333-2ef2-4dff-f43e-8e198809c8bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.13.1\n",
            "2.13.1\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import tensorflow\n",
        "print(keras.__version__)\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkWapa8NiCfp"
      },
      "outputs": [],
      "source": [
        "# Useful Constants\n",
        "\n",
        "# Output classes to learn how to classify\n",
        "LABELS = [\n",
        "    \"RUNNING\",\n",
        "    \"STANDING\",\n",
        "    \"Walking\",\n",
        "    \"Strong kicking\",\n",
        "    \"Passing\",\n",
        "\n",
        "]\n",
        "DATASET_PATH = \"/content/\"\n",
        "\n",
        "\n",
        "# x_train_path = DATASET_PATH + \"body16Raw_Train_X.csv\"\n",
        "x_train_path = DATASET_PATH + \"Raw_Train_X.csv\"\n",
        "# x_test_path = DATASET_PATH + \"body16Raw_Test_X.csv\"\n",
        "x_test_path = DATASET_PATH + \"Raw_Test_X.csv\"\n",
        "\n",
        "# x_test_path = DATASET_PATH + \"testx.csv\" #單場景測試\n",
        "\n",
        "y_train_path = DATASET_PATH + \"Raw_Train_Y.csv\"\n",
        "y_test_path = DATASET_PATH + \"Raw_Test_Y.csv\"\n",
        "\n",
        "# y_test_path = DATASET_PATH + \"testy.csv\" #單場景測試\n",
        "\n",
        "n_steps = 16    # 32 frames per series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBqp0ViFiF20"
      },
      "outputs": [],
      "source": [
        "def load_X(path):\n",
        "    data=pd.read_csv(path,header=None).values\n",
        "    blocks = int(len(data) / n_steps)\n",
        "    data=np.array(np.split(data,blocks))\n",
        "    return data\n",
        "\n",
        "def load_y(path):\n",
        "    data=pd.read_csv(path,header=None).values\n",
        "    return data-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1O5qpkeiGfW"
      },
      "outputs": [],
      "source": [
        "#Load the data\n",
        "X_train = load_X(x_train_path)\n",
        "X_test = load_X(x_test_path)\n",
        "y_train = load_y(y_train_path)\n",
        "y_test = load_y(y_test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGXAsDnwiI9i"
      },
      "outputs": [],
      "source": [
        "# Input Data\n",
        "training_data_count = len(X_train)  # 4519 training series (with 50% overlap between each serie)\n",
        "test_data_count = len(X_test)  # 1197 test series\n",
        "n_input = len(X_train[0][0])\n",
        "n_hidden = 512 # Hidden layer num of features\n",
        "n_classes = 5  #number of action classes\n",
        "\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPRxQ5wF5j46"
      },
      "outputs": [],
      "source": [
        "y_train_one_hot = to_categorical(y_train, num_classes=5)\n",
        "y_test_one_hot = to_categorical(y_test, 5)\n",
        "\n",
        "train_size = X_train.shape[0] - X_train.shape[0] % batch_size\n",
        "test_size = X_test.shape[0] - X_test.shape[0] % batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyOmcIzGiLDM"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "   Dense(n_hidden, activation='relu'),\n",
        "   BatchNormalization(),\n",
        "   LSTM(n_hidden, return_sequences=True,  unit_forget_bias=1.0,dropout=0.2),\n",
        "   LSTM(n_hidden,  unit_forget_bias=1.0),\n",
        "   BatchNormalization(),\n",
        "   Dense(n_classes,\n",
        "       activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaDhcNFaiOJb"
      },
      "outputs": [],
      "source": [
        "# #LR range test\n",
        "# clr = CyclicLR(base_lr=0.0001, max_lr=1, step_size=np.ceil(X_train.shape[0]/(batch_size)), mode='triangular')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjwFGW3OiQ52"
      },
      "outputs": [],
      "source": [
        "# model.compile(\n",
        "#    optimizer=SGD(),\n",
        "#    metrics=['accuracy'],\n",
        "#    loss='categorical_crossentropy'\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo68gn9EiUKM",
        "outputId": "b051e3bd-24c2-4ab5-9c97-3cf4423201e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 33s 1s/step - loss: 1.8919 - accuracy: 0.5605\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 26s 831ms/step - loss: 0.7233 - accuracy: 0.7641\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 25s 818ms/step - loss: 0.5469 - accuracy: 0.8044\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 27s 880ms/step - loss: 0.4770 - accuracy: 0.8306\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 25s 808ms/step - loss: 0.3951 - accuracy: 0.8649\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 26s 826ms/step - loss: 0.2790 - accuracy: 0.8851\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 25s 815ms/step - loss: 0.3372 - accuracy: 0.8790\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 27s 850ms/step - loss: 0.3140 - accuracy: 0.8992\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 26s 791ms/step - loss: 0.3505 - accuracy: 0.8972\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 25s 795ms/step - loss: 0.2439 - accuracy: 0.9234\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 25s 817ms/step - loss: 0.3355 - accuracy: 0.8931\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 25s 823ms/step - loss: 0.1971 - accuracy: 0.9435\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 27s 881ms/step - loss: 0.1309 - accuracy: 0.9556\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 25s 824ms/step - loss: 0.1601 - accuracy: 0.9577\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 25s 807ms/step - loss: 0.1248 - accuracy: 0.9637\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 26s 830ms/step - loss: 0.1832 - accuracy: 0.9456\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 27s 851ms/step - loss: 0.1466 - accuracy: 0.9577\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 25s 805ms/step - loss: 0.1650 - accuracy: 0.9476\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 25s 807ms/step - loss: 0.1369 - accuracy: 0.9637\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 26s 834ms/step - loss: 0.1935 - accuracy: 0.9375\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 27s 877ms/step - loss: 0.1133 - accuracy: 0.9819\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 26s 829ms/step - loss: 0.0965 - accuracy: 0.9698\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 26s 844ms/step - loss: 0.1271 - accuracy: 0.9617\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 26s 848ms/step - loss: 0.0963 - accuracy: 0.9698\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 27s 881ms/step - loss: 0.1142 - accuracy: 0.9657\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 26s 832ms/step - loss: 0.1037 - accuracy: 0.9698\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 25s 812ms/step - loss: 0.0698 - accuracy: 0.9819\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 26s 847ms/step - loss: 0.0900 - accuracy: 0.9637\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 27s 883ms/step - loss: 0.0867 - accuracy: 0.9657\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 26s 842ms/step - loss: 0.0911 - accuracy: 0.9718\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 26s 827ms/step - loss: 0.0888 - accuracy: 0.9778\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 25s 810ms/step - loss: 0.0889 - accuracy: 0.9758\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 28s 897ms/step - loss: 0.0739 - accuracy: 0.9738\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 26s 839ms/step - loss: 0.0861 - accuracy: 0.9657\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 26s 845ms/step - loss: 0.1137 - accuracy: 0.9718\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 26s 848ms/step - loss: 0.1460 - accuracy: 0.9617\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 27s 856ms/step - loss: 0.1071 - accuracy: 0.9718\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 27s 858ms/step - loss: 0.1169 - accuracy: 0.9536\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 26s 848ms/step - loss: 0.0716 - accuracy: 0.9778\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 24s 782ms/step - loss: 0.0565 - accuracy: 0.9798\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 26s 855ms/step - loss: 0.0707 - accuracy: 0.9839\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 27s 879ms/step - loss: 0.0847 - accuracy: 0.9738\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 26s 837ms/step - loss: 0.0560 - accuracy: 0.9819\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 26s 855ms/step - loss: 0.0882 - accuracy: 0.9778\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 26s 839ms/step - loss: 0.0311 - accuracy: 0.9919\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 28s 892ms/step - loss: 0.0789 - accuracy: 0.9879\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 26s 820ms/step - loss: 0.0374 - accuracy: 0.9919\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 26s 824ms/step - loss: 0.0262 - accuracy: 0.9960\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 27s 874ms/step - loss: 0.0184 - accuracy: 0.9940\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 28s 886ms/step - loss: 0.0299 - accuracy: 0.9940\n",
            "訓練集準確率：0.9822\n",
            "測試集準確率：0.8031\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)  # Specify the learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "\n",
        "\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# optimizer = SGD(learning_rate=0.01, momentum=0.9)  # 設置學習率和動量\n",
        "\n",
        "# from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# optimizer = RMSprop(learning_rate=0.001, rho=0.9)\n",
        "\n",
        "history = model.fit(X_train[:train_size,:,:], y_train_one_hot[:train_size,:], epochs=50, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# 訓練集準確率\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train_one_hot, verbose=0)\n",
        "print(f\"訓練集準確率：{train_accuracy:.4f}\")\n",
        "\n",
        "# 測試集準確率\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
        "print(f\"測試集準確率：{test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io3K0XHHiXKX",
        "outputId": "2aaa932f-0fbb-4bf5-e43a-fda4e8870e07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# # Save the model\n",
        "model.save('/content/adam091304.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPgmKu_xiZ8t"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model, Sequential\n",
        "from sklearn.metrics import confusion_matrix\n",
        "model = load_model('/content/adam091304.h5')\n",
        "\n",
        "# Generate predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Get the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Normalize the confusion matrix\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "# Plot the confusion matrix\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=LABELS, yticklabels=LABELS,\n",
        "       title='Confusion matrix',\n",
        "       ylabel='True label',\n",
        "       xlabel='Predicted label')\n",
        "\n",
        "# Rotate the tick labels and set their alignment.\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "fmt = '.4f'\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], fmt),\n",
        "               ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
